{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7 worksheet: SciPy and pandas for data science and statistics\n",
    "\n",
    "This week, we introduce the modules **SciPy** and **pandas**, which provide convenient tools for statistics, optimisation, and data science.\n",
    "\n",
    "The best way to learn programming is to write code. Don't hesitate to edit the code in the example cells, or add your own code, to test your understanding. You will find practice exercises throughout the notebook, denoted by ðŸš© ***Exercise $x$:***.\n",
    "\n",
    "#### Displaying solutions\n",
    "\n",
    "Solutions will be released one week after the worksheets are released, as a new `.txt` file in the same GitHub repository. After pulling the file to your workspace (either your computer or your Noteable server), run the following cell to create clickable buttons under each exercise, which will allow you to reveal the solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/create_widgets.py week07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SciPy\n",
    "\n",
    "The **SciPy** library provides a set of scientific computing tools for Python -- [it is actually a relative of Numpy](https://www.scipy.org/scipylib/faq.html#numpy-vs-scipy-vs-other-packages). I would recommend you have a browse of the documentation and tutorial linked below to get an idea of all the functionalities included. For this course, we will give a brief tour of some of SciPy's modules in action, to give you a sense of how they might be used to solve practical problems.\n",
    "\n",
    "---\n",
    "**ðŸ“š Learn more:**\n",
    "* [SciPy documentation](https://docs.scipy.org/doc/scipy/reference/)\n",
    "* [SciPy tutorial - Introduction](https://docs.scipy.org/doc/scipy/reference/tutorial/general.html)\n",
    "* [Frequently asked questions - SciPy documentation](https://www.scipy.org/scipylib/faq.html#frequently-asked-questions)\n",
    "* [Optimization](https://docs.scipy.org/doc/scipy/reference/optimize.html) - This contains functions for finding minima (or maxima) and roots of equations in one or more dimensions.\n",
    "* [Interpolation](https://docs.scipy.org/doc/scipy/reference/interpolate.html) - Contains functions for interpolating values using splines or other approximating polynomials.\n",
    "* [Statistics](https://docs.scipy.org/doc/scipy/reference/stats.html) - Many more statistics related functions.\n",
    "* [Integration](https://docs.scipy.org/doc/scipy/reference/integrate.html) - Contains functions for performing integration (using Simpson's rule and more complicated quadrature rules).\n",
    "\n",
    "---\n",
    "\n",
    "### Interpolating some noisy data\n",
    "\n",
    "Suppose we have a set of data points $(x_i, y_i)$, with coordinates stored in vectors `x` and `y`. The **`interpolate` sub-module** provides tools to interpolate data. In particular, it contains many functions for constructing piecewise polynomials, and in particular [splines](https://en.wikipedia.org/wiki/Spline_(mathematics)).\n",
    "\n",
    "Below is an example of how spline interpolation might be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import all necessary modules\n",
    "import numpy as np\n",
    "import scipy.interpolate\n",
    "import scipy as scp\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate some data that looks like a smooth curve with some \n",
    "# noise overlayed:\n",
    "def generate_data(x):\n",
    "    '''\n",
    "    Generate some smooth data (sin curve) with overlaid noise \n",
    "    coming from a Normal distribution.\n",
    "    '''\n",
    "    # Generate some noise from a Normal distribution - \n",
    "    # this generates an array of values simulated from \n",
    "    # an N(0, 0.3**2), with the array of the same length as x:\n",
    "    noise = np.random.normal(0, 0.2, len(x))\n",
    "    y = np.sin(x) + noise\n",
    "    return y\n",
    "\n",
    "# Set up x and generate y data:\n",
    "step = 0.4\n",
    "x = np.arange(0, 10 + step, step)\n",
    "y = generate_data(x)\n",
    "\n",
    "# Make an interpolating function - this one goes through all of the \n",
    "# data points, and joins them with a piecewise cubic function:\n",
    "f_interp = scp.interpolate.interp1d(x, y, kind='cubic')\n",
    "\n",
    "# Now fit a spline using a different function that takes a smoothing \n",
    "# parameter s, this spline won't go through all of the points but will \n",
    "# look smoother:\n",
    "f_smooth = scp.interpolate.UnivariateSpline(x, y, s=4)\n",
    "\n",
    "# Now suppose we want a value for y at a point in between\n",
    "# our x values - let's say x = 1.5:\n",
    "print(f_interp(1.5))\n",
    "print(f_smooth(1.5))\n",
    "\n",
    "# Make a denser x-axis to plot our interpolated functions\n",
    "xmin, xmax = x[0], x[-1]\n",
    "dense_step = 0.05\n",
    "x_dense = np.arange(xmin, xmax + dense_step, dense_step)\n",
    "\n",
    "# Plot the data\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x, y, 'k.', label='Noisy data')\n",
    "ax.plot(x_dense, np.sin(x_dense), 'g-', label='Underlying function')\n",
    "ax.plot(x_dense, f_interp(x_dense), 'c--', label='Interpolating spline')\n",
    "ax.plot(x_dense, f_smooth(x_dense), 'r-.', label='Smooth spline')\n",
    "\n",
    "ax.set_xlabel(r'$x$')\n",
    "ax.set_ylabel(r'$y$')\n",
    "ax.set_xlim([xmin, xmax])\n",
    "ax.legend(loc='upper center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the interpolating functions (here, `scp.interpolate.interp1d()` and `scp.interpolate.UnivariateSpline`) **return a function object**, which we can then call as any other function.\n",
    "\n",
    "Make sure to look up the two spline fitting functions to check you understand how the call here matches what is in the documentation.\n",
    "\n",
    "---\n",
    "***ðŸš© Exercise:***\n",
    "* Try a different function as the smooth background function from `np.sin(x)`.\n",
    "* Modify the function `generate_data()` to also take the standard deviation of the noise as input. Experiment with different values, and observe how well or poorly the splines fit the data, depending on how noisy it is.\n",
    "* Try changing the smoothing parameter `s` in the second fitted spline. How does this change the result? Can you make it look like the first interpolating spline?\n",
    "\n",
    "---\n",
    "\n",
    "### Summary statistics, reading a file\n",
    "\n",
    "Next, let's look at some descriptive statistics (means, variance, etc). To do that, we can examine some real data -- the file `oil_reserve_data.csv` should have been downloaded to your Noteable workspace (and should therefore be in the same directory as this notebook) when you fetched this week's assignment. The file is a slightly edited version of one that comes from [this EU data source](http://data.europa.eu/euodp/en/data/dataset/RH8xH4aVauYKO92JJxv8sA). It describes the emergency oil reserves kept by several European countries over recent years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Use Numpy's loadtxt function to open the data file:\n",
    "oil_data = np.loadtxt('oil_reserve_data.csv',\n",
    "                      dtype=float,\n",
    "                      delimiter=',',\n",
    "                      skiprows=1,\n",
    "                      usecols=(1, 2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have to skip a row and not use the first column in order to get a section of this file that is all of floating point type. Have a look at the file e.g. in Excel to see what it looks like. (In the next section, we will see better ways to import this type of data, using the `pandas` module.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Unpack each column into a different array named for the \n",
    "# country depicted in the data (use transpose to obtain the\n",
    "# array as a list of rows):\n",
    "germany, denmark, belgium, bulgaria = oil_data.T\n",
    "\n",
    "# Use the describe function to get basic summary statistics:\n",
    "print('stats.describe output:')\n",
    "print('Germany:\\n', stats.describe(germany))\n",
    "print('Denmark:\\n', stats.describe(denmark))\n",
    "\n",
    "# Find the 5% and 95% percentile locations:\n",
    "print('\\n5% and 95% percentiles:')\n",
    "print(np.percentile(germany, (5, 95)))\n",
    "\n",
    "# Find the Pearson's and Spearman's correlation coefficients\n",
    "# between two columns:\n",
    "print('\\nCorrelation coefficients for Germany/Denmark and Germany/Bulgaria:')\n",
    "print(stats.pearsonr(germany, denmark))\n",
    "print(stats.spearmanr(germany, bulgaria))\n",
    "\n",
    "# We can save out an array to a file using Numpy's\n",
    "# savetxt() function:\n",
    "np.savetxt('belgium.txt', belgium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "ðŸš© ***Exercise 1:***\n",
    "- What is the median value for Bulgaria? the mode? the geometric mean?\n",
    "- Try finding correlations between the different columns.\n",
    "- Can you find a linear relationship between the data from Germany and Denmark (i.e., can you fit a linear function $y = ax + b$, where $x$ is the data for Germany and $y$ the data for Bulgaria)?\n",
    "\n",
    "Look for the relevant functions in the documentation for Numpy and for `scipy.stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%run scripts/show_solutions.py week07_ex1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Optimisation\n",
    "\n",
    "The module `scipy.optimize` may be of interest for those of you interested in optimisation, for instance in operational research. For example, let's try one of the problems from [this page](http://people.brunel.ac.uk/~mastjjb/jeb/or/morelp.html):\n",
    "\n",
    "> A carpenter makes tables and chairs. Each table can be sold for a profit of Â£30 and each chair for a profit of Â£10.\n",
    "> 1. The carpenter can afford to spend up to 40 hours per week working and takes six hours to make a table and three hours to make a chair.\n",
    "> 2. Customer demand requires that they make at least three times as many chairs as tables.\n",
    "> 3. Tables take up four times as much storage space as chairs and there is room for at most four tables each week.\n",
    "\n",
    "The goal is to **maximise** the profit that the carpenter can make in 1 week, by finding the optimal number of tables $x_T$ and number of chairs $x_C$ that they should make.\n",
    "\n",
    "This is a *linear programming problem*: we need to maximise the weekly profit, given by the objective function $f(x_T, x_C) = 30x_T + 10x_C$, subject to 3 linear constraints:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "0. & & x_T &\\geq 0, x_C \\geq 0 \\\\\n",
    "1. & & 6x_T + 3x_C &\\leq 40 \\\\\n",
    "2. & & x_C &\\geq 3x_T \\\\\n",
    "3. & & x_C/4 + x_T &\\leq 4\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We can use [`scipy.optimize.linprog()`](https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html#linear-programming-linprog) to solve this problem, but first we need to rearrange it a little bit, to fit the kind of input that this function takes.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\min_{x_T, x_C} -30x_T - 10x_C, \\\\\n",
    "&\\text{such that} \\quad\n",
    "\\begin{bmatrix}\n",
    "-1 & 0 \\\\\n",
    "0 & -1 \\\\\n",
    "6 & 3 \\\\\n",
    "3 & -1 \\\\\n",
    "1 & \\frac{1}{4}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_T \\\\ x_C\n",
    "\\end{bmatrix}\n",
    "\\leq\n",
    "\\begin{bmatrix}\n",
    "0 \\\\ 0 \\\\ 40 \\\\ 0 \\\\ 4\n",
    "\\end{bmatrix}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Looking at the documentation, the default bounds on the variable values is that they are non-negative, which corresponds to our problem here -- so we don't need to specify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linprog\n",
    "\n",
    "A = np.array([[6, 3],\n",
    "              [3, -1],\n",
    "              [1, 0.25]])\n",
    "\n",
    "b = np.array([40, 0, 4], dtype=float)\n",
    "c = np.array([-30, -10], dtype=float)\n",
    "\n",
    "solution = linprog(c, A, b)\n",
    "print('Output of linprog:')\n",
    "print(solution, '\\n')\n",
    "\n",
    "results = A @ solution.x\n",
    "\n",
    "print(f'The optimal strategy is to make {solution.x[0]:.2f} tables',\n",
    "      f'and {solution.x[1]:.2f} chairs every week (on average), for',\n",
    "      f'a profit of Â£{-solution.fun:.2f} per week.',\n",
    "      f'This is {results[0]:.1f} hours of work per week, '\n",
    "      f'taking up {100*results[2]/4:.1f}% of storage space.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other optimisation and root-finding methods available in `scipy.optimise`, each more or less well-suited to different problems. When faced with such a problem, the best thing to do is to have a browse in the documentation, and find if there is perhaps a method already implemented there that you could use.\n",
    "\n",
    "---\n",
    "ðŸš© ***Exercise 2:*** The carpenter is aiming to make a profit of at least Â£150 per week, but now they have twice the storage space. What is the minimum number of hours they need to work in a week to achieve this?\n",
    "\n",
    "What if they have to make exactly 3 chairs for each table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%run scripts/show_solutions.py week07_ex2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pandas\n",
    "\n",
    "The second module we will look at today (and next week!) is **Pandas**. Pandas is a module which allows the construction of a **dataframe**, an object to store data that looks a little like a spreadsheet (the data is indexed principally by a column name and row name/number). The data contained in a dataframe does *not* have to be of the same type. \n",
    "\n",
    "---\n",
    "**ðŸ“š Learn more:**\n",
    "* [Pandas (main website)](http://pandas.pydata.org/index.html)\n",
    "* [Pandas documentation](http://pandas.pydata.org/pandas-docs/stable/).\n",
    "* [A quick introduction to Pandas](http://pandas.pydata.org/pandas-docs/stable/10min.html)\n",
    "* There is a fantastic tutorial (also in Jupyter) [here](http://pandas.pydata.org/pandas-docs/stable/tutorials.html) (under Lessons for New Pandas Users). This is well worth working through a little if you want a longer introduction to the basic concepts in Pandas.\n",
    "---\n",
    "\n",
    "Here are some basic examples, the first uses the same file `oil_reserve_data.csv` from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the pandas module\n",
    "import pandas as pd\n",
    "\n",
    "# Use the read_csv method to read the CSV file into a dataframe\n",
    "oil_data = pd.read_csv('oil_reserve_data.csv')\n",
    "\n",
    "# Look at what the dataframe contains\n",
    "oil_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column headers\n",
    "print('Column headers:')\n",
    "print(oil_data.columns, '\\n')\n",
    "\n",
    "# Pull the data from a particular column by referring to it by name\n",
    "print('Data from Germany:')\n",
    "print(oil_data['Germany'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify a column to use as row labels when reading the file -- note the difference with the previous command here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the first column in the file as row index\n",
    "oil_data = pd.read_csv('oil_reserve_data.csv', index_col=0)\n",
    "\n",
    "# Print the column names and the row names\n",
    "print(oil_data.columns)\n",
    "print(oil_data.index)\n",
    "\n",
    "# Look at what the dataframe contains\n",
    "oil_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are plenty of other optional arguments of `pd.read_csv()` which are very helpful to read CSV files with different properties and layouts -- [have a look at the documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html).\n",
    "\n",
    "---\n",
    "### Indexing dataframes\n",
    "\n",
    "[The user guide in the pandas documentation is a must-read](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html). Here is a summary:\n",
    "\n",
    "- **`.iloc`** is used for indexing by number (like in Numpy arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_data = pd.read_csv('oil_reserve_data.csv', index_col=0)\n",
    "\n",
    "# Select a row from our data, by numerical index (here, the second row)\n",
    "print(oil_data.iloc[1], '\\n')\n",
    "\n",
    "# We can also grab a column by number - here, the second column\n",
    "print(oil_data.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **`.loc`** is used for indexing by label (row or column header), and also for Boolean indexing.\n",
    "\n",
    "In the second example here:\n",
    "- we use `.loc` to return all the data for Bulgaria,\n",
    "- we create a Boolean dataframe using `<` which is `True` where the reserves for Bulgaria are below 1000,\n",
    "- we use `.index` with the Boolean array to return the names of all the **rows** (i.e. the dates) where this happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print data for June 2019 in Germany, using row and column labels\n",
    "print(oil_data.loc['2019M06', 'Germany'], '\\n')\n",
    "\n",
    "# Print the dates when the reserves in Bulgaria are below 1000\n",
    "bulgaria_below_1000 = oil_data.loc[:, 'Bulgaria'] < 1000\n",
    "print(bulgaria_below_1000, '\\n')\n",
    "print(oil_data.index[bulgaria_below_1000], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `.columns`, `.index`, `.loc` and `.iloc` **are not functions** (i.e. you don't use parentheses when using them, but square brackets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "ðŸš© ***Exercise 3:*** Display the oil reserves in Denmark, but only at the dates when the reserves in Germany are below 20000 **and** the reserves in Belgium are above 4000. [You might find this helpful...](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%run scripts/show_solutions.py week07_ex3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let us look at a different dataset. The file `r_and_d_spend.csv` comes from an [open European dataset](http://data.europa.eu/euodp/en/data/dataset/Lnlc8Fcv5u1RYlfjnsKxg) describing the GDP spend of different countries on research and development work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read in our data\n",
    "randd = pd.read_csv('r_and_d_spend.csv')\n",
    "print(randd)\n",
    "\n",
    "# Plot the data for Austria\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(randd['Year'], randd['Austria'], 'bo')\n",
    "\n",
    "# Fit a line through the Austria data\n",
    "LR_aus = st.linregress(randd['Year'], randd['Austria'])\n",
    "# slope, intercept = LR_aus[0], LR_aus[1]\n",
    "y_aus = LR_aus.intercept + LR_aus.slope * randd['Year']\n",
    "\n",
    "ax.plot(randd['Year'], y_aus, 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**ðŸ“š Learn more:**\n",
    "* [pandas.DataFrame.loc - Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html)\n",
    "* [pandas.DataFrame.iloc - Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html)\n",
    "* [Indexing, iteration - Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html#indexing-iteration)\n",
    "* [Plotting - Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html#plotting)\n",
    "* [Boolean indexing - Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing)\n",
    "\n",
    "---\n",
    "ðŸš© ***Exercise 4:*** Look at the other columns in the `r_and_d_spend.csv` file. Fit linear best fit lines to the other columns, make plots of them similar to the one shown above. Try putting them all in the same figure but on different subplots. Add legends, titles, and axis labels as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%run scripts/show_solutions.py week07_ex4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "ðŸš© ***Exercise 5:*** Plot the data for all countries on the same graph between 2000 and 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%run scripts/show_solutions.py week07_ex5"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
